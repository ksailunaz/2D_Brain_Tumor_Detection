{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN for tumor detection from input brain MRIs\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nrows = 256\n",
    "ncolumns = 256\n",
    "channels = 1\n",
    "\n",
    "path_in = \"...\"\n",
    "dir_out = \"...\"\n",
    "path_out = dir_out + \"Run/\"\n",
    "\n",
    "if not os.path.exists(path_out):\n",
    "    os.makedirs(path_out)\n",
    "    print(\"Directory Created\")\n",
    "else:    \n",
    "    print(\"Directory Already Exists\") \n",
    "\n",
    "def process_images (img_list):\n",
    "    X = [] # images\n",
    "    y = [] # labels\n",
    "    \n",
    "    for img in img_list:\n",
    "        X.append(cv2.imread(img))\n",
    "        \n",
    "        if 'Y' in img:\n",
    "            y.append(1) # 1 = Tumor\n",
    "        elif 'N' in img:\n",
    "            y.append(0) # 0 = Non-tumor\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "train_dir = path_in + 'Train'\n",
    "test_dir = path_in + 'Test'\n",
    "\n",
    "train_imgs = ['Train/{}'.format(i) for i in os.listdir(train_dir)]\n",
    "random.shuffle(train_imgs)\n",
    "\n",
    "test_imgs = ['Test/{}'.format(i) for i in os.listdir(test_dir)]\n",
    "\n",
    "#print(train_imgs)\n",
    "#print(test_imgs)\n",
    "\n",
    "# Get images and labels\n",
    "X, y = process_images(train_imgs)\n",
    "\n",
    "del train_imgs\n",
    "gc.collect()\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "#print('Shape of train images : ', X.shape)\n",
    "#print('Shape of train labels : ', y.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.20, random_state = 2)\n",
    "\n",
    "print('Shape of train images : ', X_train.shape)\n",
    "print('Shape of train labels : ', y_train.shape)\n",
    "print('Shape of validation images : ', X_val.shape)\n",
    "print('Shape of validation labels : ', y_val.shape)\n",
    "\n",
    "del X\n",
    "del y\n",
    "gc.collect()\n",
    "\n",
    "ntrain = len(X_train)\n",
    "nval = len(X_val)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# 1st Layer\n",
    "model.add(layers.Conv2D(32,(8,8),activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# 2nd Layer\n",
    "model.add(layers.Conv2D(64, (8, 8), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size = batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size = batch_size)\n",
    "\n",
    "# Training\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = 10,\n",
    "                              epochs = 50,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = 10)\n",
    "\n",
    "# Save model\n",
    "#model.save_weights(path_out + 'model_weights.h5')\n",
    "#model.save(path_out + 'model_keras.h5')\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "avg_acc = np.mean(acc) * 100\n",
    "avg_val_acc = np.mean(val_acc) * 100\n",
    "avg_loss = np.mean(loss) * 100\n",
    "avg_val_loss = np.mean(val_loss) * 100\n",
    "\n",
    "file0 = open(path_out + \"avg_eval.txt\",\"w\")#append mode \n",
    "file0.write(\"Average Training Accuracy: \" + str(avg_acc)) \n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Average Validation Accuracy: \" + str(avg_val_acc)) \n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Average Training Loss: \" + str(avg_loss)) \n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Average Validation Loss: \" + str(avg_val_loss)) \n",
    "file0.write(\"\\n\")\n",
    "file0.close()\n",
    "\n",
    "np.savetxt(path_out + 'train_acc.txt', acc, delimiter=\"\\n\") \n",
    "np.savetxt(path_out + 'val_acc.txt', val_acc, delimiter=\"\\n\") \n",
    "np.savetxt(path_out + 'train_loss.txt', loss, delimiter=\"\\n\") \n",
    "np.savetxt(path_out + 'val_loss.txt', val_loss, delimiter=\"\\n\") \n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label = 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(path_out + 'Accuracy.jpg')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(path_out + 'Loss.jpg')\n",
    "plt.show()\n",
    "\n",
    "X_test, y_test = process_images(test_imgs)\n",
    "\n",
    "num_test = len(X_test)\n",
    "\n",
    "#print('Shape of test images : ', X_test.shape)\n",
    "#print('Shape of test labels : ', y_test.shape)\n",
    "\n",
    "np.savetxt(path_out + 'y_test.txt', y_test, delimiter=\"\\n\") \n",
    "\n",
    "x = np.array(X_test)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "p = 1\n",
    "\n",
    "batch = test_datagen.flow(x)\n",
    "pred = model.predict(batch)\n",
    "\n",
    "test_eval = model.evaluate(x, y_test, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n",
    "\n",
    "test_acc = test_eval[1] * 100\n",
    "test_loss = test_eval[0] * 100\n",
    "\n",
    "file_t = open(path_out + \"test_eval.txt\",\"w\")#append mode \n",
    "file_t.write(\"Test Accuracy: \" + str(test_acc)) \n",
    "file_t.write(\"\\n\")\n",
    "file_t.write(\"Test Loss: \" + str(test_loss)) \n",
    "file_t.close() \n",
    "\n",
    "np.savetxt(path_out + 'y_prediction.txt', pred, delimiter=\"\\n\") \n",
    "\n",
    "a = 0\n",
    "\n",
    "for value in pred:\n",
    "    if (pred[a] > 0.5):\n",
    "        y_pred.append(1)\n",
    "        a = a + 1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "        a = a + 1\n",
    "        \n",
    "np.savetxt(path_out + 'y_pred.txt', y_pred, delimiter=\"\\n\")\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in range(0, num_test)):\n",
    "    a = y_test[i]\n",
    "    b = y_pred[i]\n",
    "    if(a==b):\n",
    "        c = c + 1\n",
    "    print('c: ', c)\n",
    "    \n",
    "pred_acc = (c/num_test)) * 100\n",
    "\n",
    "file1 = open(path_out + \"pred_acc.txt\",\"w\")#append mode \n",
    "file1.write(\"Correct Predictions: \" + str(c)) \n",
    "file1.write(\"\\n\")\n",
    "file1.write(\"Prediction Accuracy: \" + str(pred_acc)) \n",
    "file1.close() \n",
    "\n",
    "print('Total images in Test set :', str(num_test))\n",
    "print('Correctly predicted label: ', c)\n",
    "\n",
    "print('Prediction Accuracy : ', pred_acc)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "clsf_report = pd.DataFrame(classification_report(y_true = y_test, y_pred = y_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(path_out + 'Classification Report.csv', index= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
