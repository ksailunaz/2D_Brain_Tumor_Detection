{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect brain tumors using the features collected from the data\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, Dropout, MaxPooling1D\n",
    "\n",
    "\n",
    "path = '...'\n",
    "path_out = path + 'Run/'\n",
    "\n",
    "if not os.path.exists(path_out):\n",
    "    os.makedirs(path_out)\n",
    "    print(\"Directory Created\")\n",
    "else:    \n",
    "    print(\"Directory Already Exists\") \n",
    "\n",
    "img_dataset = np.genfromtxt(path + 'All_Features_only_values.csv', delimiter=',')\n",
    "\n",
    "num_rows = len(img_dataset)\n",
    "num_cols = len(img_dataset[0])\n",
    "\n",
    "\n",
    "X = np.zeros(shape=(num_rows, 19))\n",
    "y = np.zeros(num_rows)\n",
    "\n",
    "# Randomly shuffle read data\n",
    "random.shuffle(img_dataset)\n",
    "\n",
    "for i in range(0, num_rows):\n",
    "    X[i,0] = img_dataset[i,0]\n",
    "    X[i,1] = img_dataset[i,1]\n",
    "    X[i,2] = img_dataset[i,2]\n",
    "    X[i,3] = img_dataset[i,3]\n",
    "    X[i,4] = img_dataset[i,4]\n",
    "    X[i,5] = img_dataset[i,5]\n",
    "    X[i,6] = img_dataset[i,6]\n",
    "    X[i,7] = img_dataset[i,7]\n",
    "    X[i,8] = img_dataset[i,8]\n",
    "    X[i,9] = img_dataset[i,9]\n",
    "    X[i,10] = img_dataset[i,10]\n",
    "    X[i,11] = img_dataset[i,11]\n",
    "    X[i,12] = img_dataset[i,12]\n",
    "    X[i,13] = img_dataset[i,13]\n",
    "    X[i,14] = img_dataset[i,14]\n",
    "    X[i,15] = img_dataset[i,15]\n",
    "    X[i,16] = img_dataset[i,16]\n",
    "    X[i,17] = img_dataset[i,17]\n",
    "    X[i,18] = img_dataset[i,18]\n",
    "    y[i] = img_dataset[i,19]\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "num_train = len(y_train)\n",
    "num_test = len(y_test)\n",
    "\n",
    "X_train = np.array(X_train).astype(np.float32)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "X_test = np.array(X_test).astype(np.float32)\n",
    "y_test = np.array(y_test).astype(np.float32)\n",
    "\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size = 0.20)\n",
    "X_train1 = np.array(X_train1).astype(np.float32)\n",
    "y_train1 = np.array(y_train1).astype(np.float32)\n",
    "X_val = np.array(X_val).astype(np.float32)\n",
    "y_val = np.array(y_val).astype(np.float32)\n",
    "num_train1 = len(y_train1)\n",
    "num_val = len(y_val)\n",
    "\n",
    "print(X_train1.shape[1])\n",
    "print(X_val.shape)\n",
    "\n",
    "file0 = open(path_out + \"training_test.txt\",\"w\")#append mode \n",
    "file0.write(\"Number of total data : \" + str(num_rows)) \n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Number of training data : \" + str(num_train)) \n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Number of testing data : \" + str(num_test)) \n",
    "file0.write(\"\\n \\n \\n\")\n",
    "file0.write(\"Training data was divided into train and validation.\")\n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Number of training data (final) : \" + str(num_train1)) \n",
    "file0.write(\"\\n\")\n",
    "file0.write(\"Number of validation data : \" + str(num_val)) \n",
    "file0.close()\n",
    "print(\"Training, Validation and Test Data Splitted\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Layer\n",
    "model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(19,1)))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "# Output Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['acc'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(X_train1, y_train1, \n",
    "                    epochs = 100, \n",
    "                    validation_data = (X_val, y_val))\n",
    "\n",
    "# Save model\n",
    "model.save_weights(path_out + 'model_weights.h5')\n",
    "model.save(path_out + 'model_keras.h5')\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "avg_acc = np.mean(acc) * 100\n",
    "avg_val_acc = np.mean(val_acc) * 100\n",
    "avg_loss = np.mean(loss) * 100\n",
    "avg_val_loss = np.mean(val_loss) * 100\n",
    "file1 = open(path_out + \"avg_eval.txt\",\"w\")#append mode \n",
    "file1.write(\"Average Training Accuracy: \" + str(avg_acc)) \n",
    "file1.write(\"\\n\")\n",
    "file1.write(\"Average Validation Accuracy: \" + str(avg_val_acc)) \n",
    "file1.write(\"\\n\")\n",
    "file1.write(\"Average Training Loss: \" + str(avg_loss)) \n",
    "file1.write(\"\\n\")\n",
    "file1.write(\"Average Validation Loss: \" + str(avg_val_loss)) \n",
    "file1.close()\n",
    "\n",
    "np.savetxt(path_out + \"train_acc.txt\", acc, delimiter=\"\\n\") \n",
    "np.savetxt(path_out + \"val_acc.txt\", val_acc, delimiter=\"\\n\") \n",
    "np.savetxt(path_out + \"train_loss.txt\", loss, delimiter=\"\\n\") \n",
    "np.savetxt(path_out + \"val_loss.txt\", val_loss, delimiter=\"\\n\") \n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label = 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(path_out + \"Accuracy.jpg\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.savefig(path_out + \"Loss.jpg\")\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(path_out + \"y_test.txt\", y_test, delimiter=\"\\n\") \n",
    "\n",
    "y_pred = []\n",
    "p = 1\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "test_eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_acc = test_eval[1] * 100\n",
    "test_loss = test_eval[0] * 100\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "\n",
    "file2 = open(path_out + \"test_eval.txt\",\"w\")#append mode \n",
    "file2.write(\"Test Accuracy: \" + str(test_acc)) \n",
    "file2.write(\"\\n\")\n",
    "file2.write(\"Test Loss: \" + str(test_loss)) \n",
    "file2.close() \n",
    "\n",
    "np.savetxt(path_out + \"y_prediction.txt\", pred, delimiter=\"\\n\") \n",
    "\n",
    "a = 0\n",
    "\n",
    "for value in pred:\n",
    "    if (pred[a] > 0.5):\n",
    "        y_pred.append(1)\n",
    "        a = a + 1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "        a = a + 1\n",
    "\n",
    "np.savetxt(path_out + \"y_pred.txt\", y_pred, delimiter=\"\\n\")\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in range(0, num_test):\n",
    "    a = y_test[i]\n",
    "    b = y_pred[i]\n",
    "    if(a==b):\n",
    "        c = c + 1\n",
    "    \n",
    "pred_acc = (c/num_test) * 100\n",
    "\n",
    "file3 = open(path_out + \"pred_acc.txt\",\"w\")#append mode \n",
    "file3.write(\"Correct Predictions: \" + str(c)) \n",
    "file3.write(\"\\n\")\n",
    "file3.write(\"Prediction Accuracy: \" + str(pred_acc)) \n",
    "file3.close() \n",
    "\n",
    "print('Total images in Test set :' + str(num_test))\n",
    "print('Correctly predicted label: ', c)\n",
    "\n",
    "print('Prediction Accuracy : ', pred_acc)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "clsf_report = pd.DataFrame(classification_report(y_true = y_test, y_pred = y_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(path_out + \"Classification Report.csv\", index= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
